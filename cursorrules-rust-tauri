# Rust + Tauri Best Practices

## Rust Fundamentals

### Error Handling
```rust
// GOOD — Propagate errors with context
#[tauri::command]
async fn load_model(model_id: String, state: State<'_, AppState>) -> Result<(), String> {
    let path = state.models_dir.join(format!("ggml-{}.bin", model_id));
    if !path.exists() {
        return Err(format!("Model file not found: {}", path.display()));
    }
    // ...
    Ok(())
}

// BAD — Never do this in production
let file = File::open(path).unwrap(); // NEVER
```

### State Management in Tauri
```rust
// Define shared state with Mutex for thread safety
pub struct AppState {
    pub config: Mutex<Config>,
    pub whisper_ctx: Mutex<Option<WhisperContext>>,
    pub is_recording: AtomicBool,
    pub models_dir: PathBuf,
}

// Register in main
fn main() {
    tauri::Builder::default()
        .manage(AppState {
            config: Mutex::new(Config::default()),
            whisper_ctx: Mutex::new(None),
            is_recording: AtomicBool::new(false),
            models_dir: dirs::home_dir().unwrap().join(".whispertype/models"),
        })
        .invoke_handler(tauri::generate_handler![...])
        .run(tauri::generate_context!())
        .expect("error running tauri application");
}
```

### Async Patterns
```rust
// Audio capture runs on a dedicated std::thread (not tokio)
// because cpal callbacks are synchronous and latency-sensitive
std::thread::spawn(move || {
    let stream = device.build_input_stream(
        &config,
        move |data: &[f32], _| {
            // Push audio samples to ring buffer
            buffer_tx.send(data.to_vec()).ok();
        },
        |err| eprintln!("Audio error: {}", err),
        None,
    ).unwrap();
    stream.play().unwrap();
    std::thread::park(); // Keep thread alive
});

// Transcription runs on tokio::spawn_blocking (CPU-intensive)
tokio::spawn_blocking(move || {
    let mut state = ctx.create_state().expect("failed to create state");
    // ... process audio
})
.await
.map_err(|e| e.to_string())?;
```

### Tauri IPC Commands
```rust
// Commands = request/response (frontend calls, backend responds)
#[tauri::command]
async fn get_config(state: State<'_, AppState>) -> Result<Config, String> {
    let config = state.config.lock().map_err(|e| e.to_string())?;
    Ok(config.clone())
}

// Events = streaming (backend pushes to frontend)
app_handle.emit_all("transcription-update", TranscriptionPayload {
    text: segment.text.clone(),
    is_partial: false,
}).ok();

app_handle.emit_all("download-progress", DownloadProgress {
    model_id: model_id.clone(),
    percent: (downloaded as f64 / total as f64) * 100.0,
}).ok();
```

### Struct Patterns
```rust
use serde::{Deserialize, Serialize};

// All structs that cross IPC boundary must derive these
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Config {
    pub version: u32,
    pub hotkey: String,
    pub default_model: String,
    pub output_mode: OutputMode,
    pub audio_device: Option<String>,
    pub language: String,
    pub vad_threshold: f32,
    pub chunk_duration_ms: u32,
    pub overlap_ms: u32,
    pub downloaded_models: Vec<String>,
    pub first_run_complete: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum OutputMode {
    TypeIntoField,
    Clipboard,
    Both,
}
```

## whisper-rs Specifics

### Building with CUDA on CachyOS/Arch
```bash
# Required system packages
sudo pacman -S cuda cudnn base-devel cmake

# Cargo.toml feature flag
[dependencies]
whisper-rs = { version = "0.13", features = ["cuda"] }
```

### Model Loading Pattern
```rust
use whisper_rs::{WhisperContext, WhisperContextParameters, FullParams, SamplingStrategy};

pub fn load_whisper_model(model_path: &Path) -> Result<WhisperContext, String> {
    let mut params = WhisperContextParameters::default();
    params.use_gpu(true); // Enable CUDA

    WhisperContext::new_with_params(
        model_path.to_str().ok_or("Invalid path")?,
        params,
    ).map_err(|e| format!("Failed to load model: {}", e))
}
```

### Transcription Pattern
```rust
pub fn transcribe_audio(
    ctx: &WhisperContext,
    audio_data: &[f32], // 16kHz mono f32
    language: &str,
) -> Result<Vec<TranscriptionSegment>, String> {
    let mut state = ctx.create_state().map_err(|e| e.to_string())?;

    let mut params = FullParams::new(SamplingStrategy::Greedy { best_of: 1 });
    params.set_language(if language == "auto" { None } else { Some(language) });
    params.set_print_special(false);
    params.set_print_progress(false);
    params.set_print_realtime(false);
    params.set_print_timestamps(false);
    params.set_suppress_blank(true);
    params.set_suppress_non_speech_tokens(true);

    state.full(params, audio_data).map_err(|e| e.to_string())?;

    let num_segments = state.full_n_segments().map_err(|e| e.to_string())?;
    let mut segments = Vec::new();

    for i in 0..num_segments {
        let text = state.full_get_segment_text(i).map_err(|e| e.to_string())?;
        let start = state.full_get_segment_t0(i).map_err(|e| e.to_string())?;
        let end = state.full_get_segment_t1(i).map_err(|e| e.to_string())?;
        segments.push(TranscriptionSegment { text, start, end });
    }

    Ok(segments)
}
```

## cpal Audio Capture

### Linux-Specific Notes
```bash
# CachyOS/Arch: install ALSA development libraries
sudo pacman -S alsa-lib alsa-utils

# PipeWire (CachyOS default) works through ALSA compatibility layer
# No additional configuration needed
```

### Audio Capture Setup
```rust
use cpal::traits::{DeviceTrait, HostTrait, StreamTrait};

pub fn setup_capture(device_name: Option<&str>) -> Result<(Stream, Receiver<Vec<f32>>), String> {
    let host = cpal::default_host();

    let device = match device_name {
        Some(name) => host.input_devices()
            .map_err(|e| e.to_string())?
            .find(|d| d.name().map(|n| n == name).unwrap_or(false))
            .ok_or_else(|| format!("Device not found: {}", name))?,
        None => host.default_input_device()
            .ok_or("No default input device")?,
    };

    // Whisper expects 16kHz mono f32
    let config = cpal::StreamConfig {
        channels: 1,
        sample_rate: cpal::SampleRate(16000),
        buffer_size: cpal::BufferSize::Default,
    };

    let (tx, rx) = std::sync::mpsc::channel::<Vec<f32>>();

    let stream = device.build_input_stream(
        &config,
        move |data: &[f32], _: &cpal::InputCallbackInfo| {
            tx.send(data.to_vec()).ok();
        },
        |err| eprintln!("Audio stream error: {}", err),
        None,
    ).map_err(|e| e.to_string())?;

    Ok((stream, rx))
}
```

## File Downloads with Progress

```rust
use reqwest::Client;
use tokio::io::AsyncWriteExt;

pub async fn download_model(
    url: &str,
    dest: &Path,
    app_handle: &tauri::AppHandle,
    model_id: &str,
) -> Result<(), String> {
    let client = Client::new();
    let response = client.get(url).send().await.map_err(|e| e.to_string())?;

    let total = response.content_length().unwrap_or(0);
    let mut downloaded: u64 = 0;

    let mut file = tokio::fs::File::create(dest).await.map_err(|e| e.to_string())?;
    let mut stream = response.bytes_stream();

    use futures_util::StreamExt;
    while let Some(chunk) = stream.next().await {
        let chunk = chunk.map_err(|e| e.to_string())?;
        file.write_all(&chunk).await.map_err(|e| e.to_string())?;

        downloaded += chunk.len() as u64;
        if total > 0 {
            app_handle.emit_all("download-progress", serde_json::json!({
                "model_id": model_id,
                "percent": (downloaded as f64 / total as f64) * 100.0,
                "downloaded_bytes": downloaded,
                "total_bytes": total,
            })).ok();
        }
    }

    file.flush().await.map_err(|e| e.to_string())?;
    Ok(())
}
```

## Testing Patterns

```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_config_default() {
        let config = Config::default();
        assert_eq!(config.hotkey, "Ctrl+Shift+Space");
        assert_eq!(config.default_model, "large-v3");
    }

    #[test]
    fn test_config_serialize_roundtrip() {
        let config = Config::default();
        let json = serde_json::to_string(&config).unwrap();
        let parsed: Config = serde_json::from_str(&json).unwrap();
        assert_eq!(config.hotkey, parsed.hotkey);
    }

    #[tokio::test]
    async fn test_model_registry() {
        let models = get_model_registry();
        assert!(models.iter().any(|m| m.id == "large-v3"));
        assert!(models.iter().any(|m| m.id == "tiny"));
    }
}
```

## Performance Guidelines
- **Audio thread**: Never allocate on the audio callback thread. Pre-allocate buffers.
- **Transcription**: Use `spawn_blocking` — whisper inference is CPU/GPU-bound, not async I/O.
- **Model loading**: Takes 2-10 seconds. Always show loading state. Never block UI thread.
- **Model swapping**: Drop old WhisperContext before loading new one to free VRAM.
- **Ring buffer**: Use fixed-size circular buffer for audio, not unbounded Vec.

## Common Pitfalls
1. **Don't** use `std::sync::Mutex` across `.await` points — use `tokio::sync::Mutex` instead
2. **Don't** forget to call `stream.play()` after building cpal stream
3. **Don't** send audio data across threads without chunking — large allocations cause latency spikes
4. **Don't** forget CUDA feature flag in Cargo.toml — falls back to CPU silently
5. **Do** verify CUDA is being used: whisper-rs logs "using CUDA" on model load
